{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS269-NLG-demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+9ZR2khTXLgv/UML8U5K/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chong-z/NLG-project/blob/master/CS269_NLG_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8npvE8zXZTCl"
      },
      "source": [
        "# CS269 NLG Project: Generating Semi-Restricted Natural Language Adversarial Examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29gLB7-fZemO"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1rXH4kSYLkQ",
        "outputId": "13d62e28-cfc9-4a30-d0a8-2796b5daea9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers==3.0.2 pytorch-pretrained-bert==0.6.2 nlp torch nltk numpy tensorboardX pandas\n",
        "\n",
        "!git clone https://github.com/chong-z/NLG-project.git\n",
        "%cd NLG-project\n",
        "!sh dowloaddata.sh"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 13.0MB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert==0.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 44.8MB/s \n",
            "\u001b[?25hCollecting nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/e3/bcdc59f3434b224040c1047769c47b82705feca2b89ebbc28311e3764782/nlp-0.4.0-py3-none-any.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.8)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.7MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/9c/544396572c05841b7a2482c88be5dd54dcd18ba97abeb1e8d34daf921a54/boto3-1.16.30-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.3)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 58.4MB/s \n",
            "\u001b[?25hCollecting pyarrow>=0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 209kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (0.17.0)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.30\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/a3/1ee497faf994d180df5d14d456eef1ef46ca1ffce617816faa4ff8164608/botocore-1.19.30-py2.py3-none-any.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 44.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4fe4a33d46d08a53eb180e31e26948e1c918d0cbf9a621ab81182df46136e5d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.30 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, xxhash, pyarrow, nlp, tensorboardX\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed boto3-1.16.30 botocore-1.19.30 jmespath-0.10.0 nlp-0.4.0 pyarrow-2.0.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tensorboardX-2.1 tokenizers-0.8.1rc1 transformers-3.0.2 xxhash-2.0.0\n",
            "Cloning into 'NLG-project'...\n",
            "remote: Enumerating objects: 176, done.\u001b[K\n",
            "remote: Counting objects: 100% (176/176), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 176 (delta 90), reused 141 (delta 67), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (176/176), 31.54 MiB | 34.43 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n",
            "/content/NLG-project\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2020-12-07 00:20:01--  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
            "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
            "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34869662 (33M) [application/x-gtar]\n",
            "Saving to: ‘simple-examples.tgz’\n",
            "\n",
            "simple-examples.tgz 100%[===================>]  33.25M  4.52MB/s    in 8.4s    \n",
            "\n",
            "2020-12-07 00:20:10 (3.97 MB/s) - ‘simple-examples.tgz’ saved [34869662/34869662]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVy8sLKdd3is"
      },
      "source": [
        "## Explore SST-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "tq31xGKvd8HI",
        "outputId": "3542c376-31b1-403c-c375-82bd66c60f31"
      },
      "source": [
        "import nlp\n",
        "import pandas as pd\n",
        "pd.options.display.min_rows = 20\n",
        "pd.options.display.max_colwidth = 200\n",
        "\n",
        "sst2_data = nlp.load_dataset('glue', 'sst2')['train']\n",
        "df = pd.DataFrame(sst2_data)\n",
        "display(df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hide new secretions from the parental units</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>contains no wit , only labored gags</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>that loves its characters and communicates something rather beautiful about human nature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>remains utterly satisfied to remain the same throughout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>on the worst revenge-of-the-nerds clichés the filmmakers could dredge up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>that 's far too tragic to merit such superficial treatment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of saucy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>a depressed fifteen-year-old 's suicidal poetry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>are more deeply thought through than in most ` right-thinking ' films</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67339</th>\n",
              "      <td>67339</td>\n",
              "      <td>1</td>\n",
              "      <td>works more often than it does n't .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67340</th>\n",
              "      <td>67340</td>\n",
              "      <td>1</td>\n",
              "      <td>at least passably</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67341</th>\n",
              "      <td>67341</td>\n",
              "      <td>0</td>\n",
              "      <td>i also believe that resident evil is not it .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67342</th>\n",
              "      <td>67342</td>\n",
              "      <td>0</td>\n",
              "      <td>seem to be in a contest to see who can out-bad-act the other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67343</th>\n",
              "      <td>67343</td>\n",
              "      <td>1</td>\n",
              "      <td>showing off his doctorate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67344</th>\n",
              "      <td>67344</td>\n",
              "      <td>1</td>\n",
              "      <td>a delightful comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67345</th>\n",
              "      <td>67345</td>\n",
              "      <td>0</td>\n",
              "      <td>anguish , anger and frustration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67346</th>\n",
              "      <td>67346</td>\n",
              "      <td>1</td>\n",
              "      <td>at achieving the modest , crowd-pleasing goals it sets for itself</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67347</th>\n",
              "      <td>67347</td>\n",
              "      <td>1</td>\n",
              "      <td>a patient viewer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67348</th>\n",
              "      <td>67348</td>\n",
              "      <td>0</td>\n",
              "      <td>this new jangle of noise , mayhem and stupidity must be a serious contender for the title .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67349 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         idx  ...                                                                                                                                               sentence\n",
              "0          0  ...                                                                                                           hide new secretions from the parental units \n",
              "1          1  ...                                                                                                                   contains no wit , only labored gags \n",
              "2          2  ...                                                              that loves its characters and communicates something rather beautiful about human nature \n",
              "3          3  ...                                                                                               remains utterly satisfied to remain the same throughout \n",
              "4          4  ...                                                                              on the worst revenge-of-the-nerds clichés the filmmakers could dredge up \n",
              "5          5  ...                                                                                            that 's far too tragic to merit such superficial treatment \n",
              "6          6  ...  demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . \n",
              "7          7  ...                                                                                                                                              of saucy \n",
              "8          8  ...                                                                                                       a depressed fifteen-year-old 's suicidal poetry \n",
              "9          9  ...                                                                                 are more deeply thought through than in most ` right-thinking ' films \n",
              "...      ...  ...                                                                                                                                                    ...\n",
              "67339  67339  ...                                                                                                                   works more often than it does n't . \n",
              "67340  67340  ...                                                                                                                                     at least passably \n",
              "67341  67341  ...                                                                                                         i also believe that resident evil is not it . \n",
              "67342  67342  ...                                                                                          seem to be in a contest to see who can out-bad-act the other \n",
              "67343  67343  ...                                                                                                                             showing off his doctorate \n",
              "67344  67344  ...                                                                                                                                   a delightful comedy \n",
              "67345  67345  ...                                                                                                                       anguish , anger and frustration \n",
              "67346  67346  ...                                                                                     at achieving the modest , crowd-pleasing goals it sets for itself \n",
              "67347  67347  ...                                                                                                                                      a patient viewer \n",
              "67348  67348  ...                                                           this new jangle of noise , mayhem and stupidity must be a serious contender for the title . \n",
              "\n",
              "[67349 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p_ntouCbV-X"
      },
      "source": [
        "## Run adversarial attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LAOJJMrcUOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac49eb64-9d82-4bd4-f1bc-dbe2fc07990e"
      },
      "source": [
        "!python semi_attack.py -c models/sample-GRU/E9.pytorch --iter 2 --steps 10 --rseed 7 --most_similar -v \\\n",
        "  --victim_model \"distilbert-base-uncased-finetuned-sst-2-english\" \\\n",
        "  --victim_sentence \"i study at ucla\" \\\n",
        "  --reference_sentence \"i finished my final exam at ucla\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-07 00:35:30.732643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Model loaded from models/sample-GRU/E9.pytorch\n",
            "\n",
            "-------Initial Inputs-------\n",
            "Victim Sentence: i study at ucla pred:0.8251549005508423\n",
            "Reference Sentence: i finished my final exam at ucla pred:0.07655958086252213\n",
            "\n",
            "-------ITERATION 0-------\n",
            "Best Adv Sentence: i finished my final exam at ucla pred:0.07655958086252213\n",
            "-------PREDICTIONS-------\n",
            "0.825 & i study at ucla \\\\\n",
            "0.000 & a movie filled with unlikable , spiteful idiots  \\\\\n",
            "1.000 & a movie that will enthrall the whole family  \\\\\n",
            "0.003 & i ' ve seen before i saw this movie ,  \\\\\n",
            "0.000 & i saw this movie , i think it ' s just another crime movie  \\\\\n",
            "0.001 & i saw this movie with a taste for exaggeration  \\\\\n",
            "0.994 & i saw this movie with a taste  \\\\\n",
            "0.982 & i saw this movie with it  \\\\\n",
            "0.992 & i saw this movie  \\\\\n",
            "0.077 & i finished my final exam at ucla \\\\\n",
            "\n",
            "-------ITERATION 1-------\n",
            "Best Adv Sentence: a movie filled with unlikable , spiteful idiots <eos> pred:0.00024062106967903674\n",
            "-------PREDICTIONS-------\n",
            "0.825 & i study at ucla \\\\\n",
            "0.000 & this woefully hackneyed movie with flailing bodily movements  \\\\\n",
            "1.000 & a delicious crime drama  \\\\\n",
            "1.000 & a delicious , quirky movie  \\\\\n",
            "0.000 & a movie filled with unlikable , spiteful idiots  \\\\\n",
            "-------Attack Result-------\n",
            "Victim Sentence: i study at ucla pred:0.8251549005508423\n",
            "Best Adv Sentence: this woefully hackneyed movie with flailing bodily movements <eos> pred:0.00024062106967903674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBWAP3MjZKm0",
        "outputId": "cddde0b2-c572-4562-8f93-b3c4e3ccfc45"
      },
      "source": [
        "!python semi_attack.py -c models/sample-GRU/E9.pytorch --iter 2 --steps 10 --rseed 3 --most_similar -v \\\n",
        "  --victim_model \"distilbert-base-uncased-finetuned-sst-2-english\" \\\n",
        "  --victim_sentence \"a strangely compelling and brilliantly acted psychological drama .\" \\\n",
        "  --reference_sentence \"an absurdist sitcom about alienation , separation and loss .\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-07 00:34:59.552950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Model loaded from models/sample-GRU/E9.pytorch\n",
            "\n",
            "-------Initial Inputs-------\n",
            "Victim Sentence: a strangely compelling and brilliantly acted psychological drama . pred:0.999883770942688\n",
            "Reference Sentence: an absurdist sitcom about alienation , separation and loss . pred:0.00250418484210968\n",
            "\n",
            "-------ITERATION 0-------\n",
            "Best Adv Sentence: an absurdist sitcom about alienation , separation and loss . pred:0.00250418484210968\n",
            "-------PREDICTIONS-------\n",
            "1.000 & a strangely compelling and brilliantly acted psychological drama . \\\\\n",
            "0.999 & a quietly introspective portrait of pure misogynist evil  \\\\\n",
            "1.000 & a quietly moving portrait of an intelligent screenplay  \\\\\n",
            "0.999 & an intriguing story , but ultimately purposeless and satisfying heroine  \\\\\n",
            "0.001 & an intriguing story , but ultimately purposeless , and ultimately empty examination of the modern rut of the entire scenario .  \\\\\n",
            "1.000 & an intriguing story , but the story simply because it is a refreshingly forthright one .  \\\\\n",
            "0.003 & an absurdist sitcom about alienation , separation and loss . \\\\\n",
            "\n",
            "-------ITERATION 1-------\n",
            "Best Adv Sentence: an intriguing story , but ultimately purposeless , and ultimately empty examination of the modern rut of the entire scenario . <eos> pred:0.0007369006052613258\n",
            "-------PREDICTIONS-------\n",
            "1.000 & a strangely compelling and brilliantly acted psychological drama . \\\\\n",
            "1.000 & a delicious crime drama that revives the free-wheeling noir spirit of its spirit with its own cuteness  \\\\\n",
            "1.000 & a delicious crime drama that manages to invest its target audience talked the experience of its own ironic implications .  \\\\\n",
            "1.000 & a delicious crime drama that manages to invest its target audience talked the buoyant energy of surprise .  \\\\\n",
            "0.953 & a quietly introspective portrait of a subculture hell-bent on the emptiness of creating a screenplay  \\\\\n",
            "1.000 & the premise of a handsome and well-made entertainment  \\\\\n",
            "0.001 & the story is bogus and directed by joel schumacher and a half dozen young men who has been overexposed , redolent of the plot device  \\\\\n",
            "0.001 & the story is bogus and directed by joel schumacher and a half dozen young men who has been overexposed , redolent of the plot device .  \\\\\n",
            "1.000 & the story is pushed into the margins of a handsome and well-made entertainment .  \\\\\n",
            "0.237 & the awkwardly paced and the euphoria of the pool with its exquisite acting , inventive screenplay and listless direction .  \\\\\n",
            "0.001 & an intriguing story , but ultimately purposeless , and ultimately empty examination of the modern rut of the entire scenario .  \\\\\n",
            "-------Attack Result-------\n",
            "Victim Sentence: a strangely compelling and brilliantly acted psychological drama . pred:0.999883770942688\n",
            "Best Adv Sentence: the story is bogus and directed by joel schumacher and a half dozen young men who has been overexposed , redolent of the plot device <eos> pred:0.0007369006052613258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxO9JcbFY3Tf",
        "outputId": "7248c02a-8de6-4160-aab8-40c0ec259922"
      },
      "source": [
        "!python semi_attack.py -c models/sample-GRU/E9.pytorch --iter 2 --steps 10 --rseed 7 --most_similar -v \\\n",
        "  --victim_model \"distilbert-base-uncased-finetuned-sst-2-english\" \\\n",
        "  --victim_sentence \"a gorgeous , high-spirited musical from india that exquisitely mixed music , dance , song , and high drama .\" \\\n",
        "  --reference_sentence \"i finished my final exam at ucla\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-07 00:30:42.319395: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Model loaded from models/sample-GRU/E9.pytorch\n",
            "\n",
            "-------Initial Inputs-------\n",
            "Victim Sentence: a gorgeous , high-spirited musical from india that exquisitely mixed music , dance , song , and high drama . pred:0.9998873472213745\n",
            "Reference Sentence: i finished my final exam at ucla pred:0.07655958086252213\n",
            "\n",
            "-------ITERATION 0-------\n",
            "Best Adv Sentence: i finished my final exam at ucla pred:0.07655958086252213\n",
            "-------PREDICTIONS-------\n",
            "1.000 & a gorgeous , high-spirited musical from india that exquisitely mixed music , dance , song , and high drama . \\\\\n",
            "0.998 & a confluence , heady jumble of effectively creepy-scary , and dance , and dance , and the whole slo-mo , double-pistoled , ballistic-pyrotechnic hong kong action sequences  \\\\\n",
            "0.559 & a smart , steamy mix of sulky teen comedy that plays like a 95 - minute commercial for nba properties .  \\\\\n",
            "1.000 & a smart , steamy mix of sulky teen comedy that will have a surprising winner with the audience .  \\\\\n",
            "0.001 & a zippy 96 , but no real sense of suspense , dumb and damaged dreams  \\\\\n",
            "0.998 & a movie that will leave you wanting more than franchise possibilities ,  \\\\\n",
            "0.998 & a movie that will leave you wanting more than franchise possibilities  \\\\\n",
            "0.004 & this odd , poetic road movie that feels more like a travel-agency sitcom replete with stereotypical familial quandaries  \\\\\n",
            "0.004 & i saw this movie , offering instead of the ties  \\\\\n",
            "0.660 & i saw this movie , offering instead of the gross-out comedy  \\\\\n",
            "0.982 & i saw this movie with it  \\\\\n",
            "0.992 & i saw this movie  \\\\\n",
            "0.077 & i finished my final exam at ucla \\\\\n",
            "\n",
            "-------ITERATION 1-------\n",
            "Best Adv Sentence: a zippy 96 , but no real sense of suspense , dumb and damaged dreams <eos> pred:0.0007554199546575546\n",
            "-------PREDICTIONS-------\n",
            "1.000 & a gorgeous , high-spirited musical from india that exquisitely mixed music , dance , song , and high drama . \\\\\n",
            "1.000 & a solid , anguished performance that eclipses nearly everything else she ' s done done before while peppering the pages with memorable zingers .  \\\\\n",
            "1.000 & a solid , anguished performance that eclipses nearly everything else she ' s done before  \\\\\n",
            "0.014 & a sensitive ensemble comedy that plays like a loosely-connected string of acting-workshop exercises  \\\\\n",
            "1.000 & a sensitive ensemble comedy , with jaw-dropping action sequences , striking villains ,  \\\\\n",
            "1.000 & a sensitive , modest and quietly affecting portrait of a subculture  \\\\\n",
            "1.000 & a sensitive , modest tragedy with an almost constant mindset of suspense  \\\\\n",
            "1.000 & a sensitive , modest tragedy with an almost energy , poignancy , intelligence and verve  \\\\\n",
            "0.997 & a sensitive , modest tragedy ,  \\\\\n",
            "0.001 & a zippy 96 , but no real sense of suspense , dumb and damaged dreams  \\\\\n",
            "-------Attack Result-------\n",
            "Victim Sentence: a gorgeous , high-spirited musical from india that exquisitely mixed music , dance , song , and high drama . pred:0.9998873472213745\n",
            "Best Adv Sentence: a sensitive ensemble comedy that plays like a loosely-connected string of acting-workshop exercises <eos> pred:0.0007554199546575546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVgqK6wK4__1"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}